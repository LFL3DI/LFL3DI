{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TauLidarCommon.frame import FrameType, Frame\n",
    "from TauLidarCamera.camera import Camera\n",
    "from TauLidarCamera.constants import VALUE_20MHZ\n",
    "from TauLidarCommon.color import ColorMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraInfo = camera.info()\n",
    "\n",
    "print(\"\\nToF camera opened successfully:\")\n",
    "print(\"    model:      %s\" % cameraInfo.model)\n",
    "print(\"    firmware:   %s\" % cameraInfo.firmware)\n",
    "print(\"    uid:        %s\" % cameraInfo.uid)\n",
    "print(\"    resolution: %s\" % cameraInfo.resolution)\n",
    "print(\"    port:       %s\" % cameraInfo.port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.setModulationChannel(0) ## autoChannelEnabled: 0, channel: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.setIntegrationTime3d(0, 800)  ## set integration time 0: 1000\n",
    "camera.setMinimalAmplitude(0, 60)  ## set minimal amplitude 0: 80\n",
    "Camera.setRange(0, 4500) ## points in the distance range to be colored\n",
    "camera.setIntegrationTimeGrayscale(15000)  ## set integration time grayscale: 8000, needed when requiring FrameType.DISTANCE_GRAYSCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = camera.readFrame(FrameType.DISTANCE)\n",
    "frame = camera.readFrame(FrameType.DISTANCE_GRAYSCALE)\n",
    "frame = camera.readFrame(FrameType.DISTANCE_AMPLITUDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = camera.readFrame(FrameType.DISTANCE_AMPLITUDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING WITH YOLOV5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the YOLOv8s model\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "# If you have the custom model. Provide the absolute path to run the custom model\n",
    "# path = \"C://Users//jaura//Downloads//runs//detect//yolov8s_custom11//weights//best.pt\"\n",
    "# model = YOLO(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Start capturing video\n",
    "try:\n",
    "    while True:\n",
    "        # Read a frame from the camera\n",
    "        frame = camera.readFrame(FrameType.DISTANCE_AMPLITUDE)\n",
    "        mat_amplitude = np.frombuffer(frame.data_amplitude, dtype=np.float32, count=-1, offset=0).reshape(frame.height, frame.width)\n",
    "\n",
    "        # Convert to 8-bit for display\n",
    "        # Normalize the image for better visualization\n",
    "        cv2.normalize(mat_amplitude, mat_amplitude, 0, 255, cv2.NORM_MINMAX)\n",
    "        mat_amplitude = mat_amplitude.astype(np.uint8)\n",
    "\n",
    "        # Apply a colormap to the image\n",
    "        colored_image = cv2.applyColorMap(mat_amplitude, cv2.COLORMAP_JET)\n",
    "\n",
    "        # Perform object detection\n",
    "        results = model.predict(source=colored_image, conf=0.5)  # Confidence threshold\n",
    "\n",
    "        # Define a list of colors for different classes\n",
    "        colors = [(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) for _ in range(len(model.names))]\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes  # Bounding box predictions\n",
    "            for box in boxes:\n",
    "                # Convert tensor to a NumPy array and extract coordinates\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "\n",
    "                # Extract confidence and class ID\n",
    "                conf = box.conf[0].item()  # Confidence score\n",
    "                cls = int(box.cls[0].item())  # Class ID\n",
    "\n",
    "                # Generate the label\n",
    "                label = f\"{model.names[cls]}: {conf:.2f}\"\n",
    "\n",
    "                # Get a unique color for the class\n",
    "                box_color = colors[cls]\n",
    "                text_color = (255 - box_color[0], 255 - box_color[1], 255 - box_color[2])  # Invert box color for text\n",
    "\n",
    "                # Draw the box and label on the image\n",
    "                cv2.rectangle(colored_image, (x1, y1), (x2, y2), box_color, 2)  # Box with unique color\n",
    "                cv2.putText(colored_image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.3, text_color, 1)  # Smaller font size\n",
    "\n",
    "\n",
    "        # Enlarge the image while preserving aspect ratio\n",
    "        target_width = 1200  # Desired width\n",
    "        target_height = 1000  # Desired height\n",
    "        resized_image = cv2.resize(colored_image, (target_width, target_height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Display the colored image with bounding boxes\n",
    "        cv2.imshow('Object Detection on Depth Map', resized_image)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "finally:\n",
    "    # Release resources and close the window\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
